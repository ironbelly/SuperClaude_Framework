# Proposed Approach: Refactoring `/sc:analyze` with Auggie MCP Integration

**Version**: 2.0.0
**Date**: 2026-01-26
**Status**: Spec-Panel Reviewed - Ready for Implementation
**Authors**: Architect, Analyzer, Performance Engineering Personas
**Reviewers**: Wiegers (Requirements), Fowler (Architecture), Nygard (Reliability), Adzic (Examples), Crispin (Testing)

---

## Executive Summary

This document proposes a comprehensive refactoring of the `/sc:analyze` command to incorporate the Auggie MCP (`mcp__auggie-mcp__codebase-retrieval`) tool, transforming it from a basic pattern-matching utility into a semantically-aware code analysis engine with user-controllable aggressiveness levels.

### Key Benefits
- **40-70% token reduction** through targeted semantic retrieval vs. grep+read
- **50% latency improvement** via parallel query execution
- **2-3x precision improvement** with semantic understanding vs. text patterns
- **Support for large codebases** (1M+ LOC) through hierarchical narrowing
- **User-controllable aggressiveness** for balancing thoroughness vs. speed

### 10 Improvements Incorporated (by ROI Score)

| Priority | Improvement | ROI | Section |
|----------|-------------|-----|---------|
| P1 | Progressive Disclosure Evidence | 7.01 | Â§7 |
| P1 | Tier Classification Integration | 6.83 | Â§6 |
| P1 | Cross-Session Analysis Memory | 6.71 | Â§13 |
| P2 | Adaptive Token Budgeting | 6.50 | Â§8 |
| P2 | Language-Aware Query Templates | 6.43 | Â§9 |
| P2 | Iterative Query Refinement | 6.23 | Â§10 |
| P2 | Hybrid Validation Pipeline | 6.11 | Â§11 |
| P2 | --aggressiveness Flag | 6.10 | Â§5 |
| P3 | Auggie Result Quality Scoring | 5.53 | Â§12 |
| P3 | Real-Time Degradation Feedback | 5.42 | Â§14 |

---

## 1. Current State Analysis

### Current `/sc:analyze` Limitations

| Aspect | Current State | Impact |
|--------|---------------|--------|
| **MCP Integration** | `mcp-servers: []` | No semantic capabilities |
| **Personas** | `personas: []` | No domain expertise activation |
| **Complexity** | `complexity: basic` | Underestimates analysis needs |
| **Tool Chain** | Glob, Grep, Read, Bash, Write | Syntactic-only, high false positives |
| **Token Usage** | 15-200K per analysis | Wasteful, slow feedback |
| **Aggressiveness** | None | No user control over query intensity |

### Root Cause: Syntactic vs. Semantic Gap

The fundamental weakness is relying on Grep-based pattern matching:
- `grep "password"` finds comments, variables, AND security issues equally
- ~50% false positive rate wastes analyst time
- No cross-reference understanding
- No language-aware analysis

### Reference: `/sc:task-unified` Integration Pattern

```yaml
# How sc:task-unified integrates Auggie MCP successfully:
STRICT Execution:
  3. Load codebase context (mcp__auggie-mcp__codebase-retrieval)
  6. find_referencing_symbols (Serena MCP)
  7. Identify all files that import changed code
```

---

## 2. Proposed Architecture

### High-Level Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SEMANTIC ANALYSIS PIPELINE v2.0                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   CLASSIFY   â”‚ â†’ â”‚   DISCOVER    â”‚ â†’ â”‚   ANALYZE    â”‚ â†’ â”‚  SYNTHESIZE â”‚  â”‚
â”‚  â”‚   + CONFIG   â”‚   â”‚   + ITERATE   â”‚   â”‚   + VALIDATE â”‚   â”‚  + REPORT   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â†“                  â†“                   â†“                  â†“          â”‚
â”‚   â€¢ directory_path   â€¢ Auggie MCP        â€¢ Serena MCP      â€¢ Sequential     â”‚
â”‚   â€¢ --aggressiveness â€¢ Query Templates   â€¢ Hybrid Valid.   â€¢ write_memory   â”‚
â”‚   â€¢ Tier Detection   â€¢ Iterative Refine  â€¢ Quality Score   â€¢ Prog. Discl.   â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              ADAPTIVE TOKEN BUDGETING LAYER                             â”‚ â”‚
â”‚  â”‚   small: 100% base | medium: 150% | large: 200% | massive: 250%         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚          FALLBACK LAYER (Native Tools + Degradation Feedback)           â”‚ â”‚
â”‚  â”‚          Glob â†’ Grep â†’ Read â†’ Write | "âš ï¸ Fallback mode active"         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Design Principles

1. **Semantic-First**: Use `mcp__auggie-mcp__codebase-retrieval` as primary discovery mechanism
2. **Layered Fallback**: Graceful degradation to native tools with user feedback
3. **Parallel Execution**: Context loading and discovery run concurrently
4. **Progressive Depth**: Shallow queries first, deeper analysis only where needed
5. **Evidence Chains**: Every finding backed by verifiable source with progressive disclosure
6. **User Control**: --aggressiveness flag for tuning query intensity
7. **Tier Integration**: Leverage sc:task-unified tier classification

---

## 3. Updated Command Specification

### Proposed YAML Header

```yaml
---
name: analyze
description: "Semantic code analysis across quality, security, performance, and architecture domains"
category: utility
complexity: standard                     # UPGRADED from basic
mcp-servers: [mcp__auggie-mcp__codebase-retrieval, mcp__sequential-thinking__sequentialthinking]
mcp-optional: [serena]                   # For symbol-level analysis
personas: [analyzer, security, performance, architect]
fallback-enabled: true                   # Graceful degradation
tier-classification: auto                # NEW: Integration with sc:task-unified
progressive-disclosure: true             # NEW: Summary â†’ Details â†’ Evidence
---
```

### Enhanced Behavioral Flow

```yaml
behavioral_flow:
  1_classify_and_configure:
    action: "Determine codebase size, tier classification, and configure aggressiveness"
    tools: [mcp__auggie-mcp__codebase-retrieval]
    parameters:
      directory_path: "{project_root}"   # REQUIRED - auto-detected
      information_request: "Project structure, size, and primary languages"
    outputs:
      - codebase_size_tier: small|medium|large|massive
      - detected_languages: [list]
      - tier_classification: STRICT|STANDARD|LIGHT|EXEMPT
      - token_budget: adaptive_calculation
    budget: 1000 tokens

  2_discover_with_iteration:
    action: "Semantic discovery with iterative query refinement"
    tools: [mcp__auggie-mcp__codebase-retrieval]
    parameters:
      directory_path: "{project_root}"   # REQUIRED
      information_request: "{language_aware_query}"
    iteration:
      initial_query: "broad semantic query for {focus}"
      refinement_threshold: quality_score < 0.7
      max_iterations: 3
      refinement_strategy: "narrow scope based on initial results"
    execution: parallel
    budget: adaptive (see Â§8)

  3_analyze_with_validation:
    action: "Deep analysis with hybrid validation pipeline"
    tools: [mcp__auggie-mcp__codebase-retrieval, find_symbol, find_referencing_symbols, Grep]
    validation_chain:
      step_1: "Auggie semantic match"
      step_2: "Serena symbol verification"
      step_3: "Grep syntactic confirmation"
    quality_scoring: true
    execution: "wave pattern with checkpoints"
    budget: adaptive (see Â§8)

  4_synthesize_with_memory:
    action: "Aggregate findings with cross-session memory"
    tools: [mcp__sequential-thinking__sequentialthinking, write_memory]
    memory_operations:
      - read_previous: "analysis_{project_hash}"
      - compare_delta: "new vs previous findings"
      - write_current: "analysis_{project_hash}_{timestamp}"
    budget: 1500 tokens

  5_report_with_progressive_disclosure:
    action: "Generate actionable recommendations with tiered detail"
    tools: [write]
    output_tiers:
      summary: "Executive summary with key findings"
      details: "Expanded findings with context"
      evidence: "Full evidence chains with code snippets"
    budget: 2000 tokens
```

---

## 4. Depth Tier Mapping

### Tier Definition Matrix

| Aspect | `--depth quick` | `--depth deep` | `--depth comprehensive` |
|--------|-----------------|----------------|-------------------------|
| **Time Budget** | 15-30s | 45-90s | 2-5 min |
| **Base Token Budget** | 5-8K | 15-25K | 30-50K |
| **Auggie Queries** | 1-2 | 5-10 | 15-25 |
| **Serena Usage** | None | Targeted | Extensive |
| **Validation** | None | Spot-check | Full Grep validation |
| **Output** | Summary only | Summary + Details | Summary + Details + Evidence |
| **Iterative Refinement** | None | 1 iteration max | 3 iterations max |

### Query Strategy by Depth

**Quick (Smoke Test)**
```yaml
quick_strategy:
  auggie_queries: 1-2
  query_template: "High-level overview of {focus} concerns in {language}"
  output_tier: summary
  validation: none
  confidence: "Low - suitable for quick checks only"
  iterative_refinement: disabled
```

**Deep (Standard Analysis)**
```yaml
deep_strategy:
  auggie_queries: 5-10
  phases:
    - context: "Project architecture and main components"
    - focus_specific: 3-5 language-aware queries per focus area
    - cross_reference: "find_referencing_symbols for impact"
  output_tier: summary + details
  validation: "30-50% of findings via hybrid pipeline"
  iterative_refinement: max_1_iteration
```

**Comprehensive (Full Audit)**
```yaml
comprehensive_strategy:
  auggie_queries: 15-25
  phases:
    - context: 3 project-level queries
    - discovery: 10+ focus-specific language-aware queries
    - deep_dive: Root cause and historical pattern queries
  serena_integration: "All significant findings"
  sequential_integration: "Complex multi-step reasoning"
  output_tier: summary + details + evidence
  validation: "100% critical, 80% high, 50% medium via hybrid pipeline"
  iterative_refinement: max_3_iterations
```

---

## 5. Aggressiveness Control System (NEW - ROI 6.10)

### --aggressiveness Flag Specification

```yaml
aggressiveness_levels:
  minimal:
    description: "Conservative analysis for quick feedback"
    auggie_multiplier: 0.5x
    token_multiplier: 0.7x
    query_depth: shallow
    validation: none
    use_case: "Quick sanity checks, CI pipelines"

  balanced:
    description: "Default balanced analysis (recommended)"
    auggie_multiplier: 1.0x
    token_multiplier: 1.0x
    query_depth: moderate
    validation: spot-check
    use_case: "Standard development workflow"

  aggressive:
    description: "Thorough analysis for important changes"
    auggie_multiplier: 1.5x
    token_multiplier: 1.3x
    query_depth: deep
    validation: hybrid_pipeline
    use_case: "Pre-merge reviews, security-sensitive code"

  maximum:
    description: "Exhaustive analysis for critical audits"
    auggie_multiplier: 2.0x
    token_multiplier: 1.5x
    query_depth: exhaustive
    validation: full_hybrid + manual_review
    use_case: "Security audits, compliance reviews, production deployments"
```

### Aggressiveness Ã— Depth Matrix

| Depth | minimal | balanced | aggressive | maximum |
|-------|---------|----------|------------|---------|
| quick | 1 query, 3K tokens | 2 queries, 6K tokens | 3 queries, 8K tokens | 4 queries, 10K tokens |
| deep | 3 queries, 10K tokens | 7 queries, 20K tokens | 12 queries, 30K tokens | 18 queries, 40K tokens |
| comprehensive | 8 queries, 25K tokens | 20 queries, 40K tokens | 35 queries, 60K tokens | 50 queries, 80K tokens |

### Usage Examples

```bash
# Quick security check before commit
/sc:analyze @src --focus security --depth quick --aggressiveness minimal

# Standard development workflow (defaults)
/sc:analyze @src --focus quality

# Pre-merge thorough review
/sc:analyze @src --focus security,quality --depth deep --aggressiveness aggressive

# Production deployment audit
/sc:analyze @src --depth comprehensive --aggressiveness maximum
```

---

## 6. Tier Classification Integration (NEW - ROI 6.83)

### Integration with sc:task-unified

```yaml
tier_classification_integration:
  purpose: "Automatically adjust analysis rigor based on task tier"

  mapping:
    STRICT:
      description: "Security, auth, database, multi-file refactoring"
      auto_aggressiveness: aggressive
      auto_depth: deep minimum
      validation: mandatory_hybrid
      evidence: full_chains_required

    STANDARD:
      description: "Single-file code changes, feature implementation"
      auto_aggressiveness: balanced
      auto_depth: deep
      validation: spot_check
      evidence: summary_with_details

    LIGHT:
      description: "Minor fixes, formatting, comments"
      auto_aggressiveness: minimal
      auto_depth: quick
      validation: none
      evidence: summary_only

    EXEMPT:
      description: "Documentation, exploration, questions"
      auto_aggressiveness: minimal
      auto_depth: quick
      validation: none
      evidence: summary_only
```

### Auto-Detection Rules

```yaml
tier_detection:
  STRICT_triggers:
    - file_patterns: ["*auth*", "*security*", "*crypto*", "*password*"]
    - keywords: ["vulnerability", "injection", "authentication"]
    - multi_file_scope: "> 3 files"
    - database_access: detected

  STANDARD_triggers:
    - single_file_change: true
    - feature_implementation: detected
    - bug_fix: detected

  LIGHT_triggers:
    - typo_fix: detected
    - comment_only: true
    - formatting_only: true

  EXEMPT_triggers:
    - documentation_only: true
    - exploration_query: detected
    - question_format: detected

  override:
    user_flag: "--tier STRICT|STANDARD|LIGHT|EXEMPT"
    reason_required: true for downgrade
```

---

## 7. Progressive Disclosure Evidence System (NEW - ROI 7.01)

### Three-Tier Output Structure

```yaml
progressive_disclosure:
  tier_1_summary:
    purpose: "Executive overview for quick decisions"
    content:
      - finding_count: "X critical, Y high, Z medium"
      - top_3_findings: "Brief one-line descriptions"
      - overall_health: "Score 0-100 with trend indicator"
      - action_required: "Yes/No with urgency level"
    token_budget: 500-800

  tier_2_details:
    purpose: "Developer-focused actionable information"
    content:
      - all_findings: "With file:line references"
      - context: "Why this is a problem"
      - impact: "What could go wrong"
      - fix_suggestion: "How to address it"
    token_budget: 1500-3000
    expansion_trigger: "User requests 'show details' or --verbose"

  tier_3_evidence:
    purpose: "Full audit trail for compliance and verification"
    content:
      - code_snippets: "Actual problematic code"
      - cross_references: "All related symbols and files"
      - validation_chain: "Auggie â†’ Serena â†’ Grep results"
      - confidence_scores: "Per-finding quality metrics"
      - historical_context: "Previous analysis comparisons"
    token_budget: 3000-8000
    expansion_trigger: "User requests 'show evidence' or --evidence"
```

### Output Format Example

```markdown
## Analysis Summary (Tier 1)
ğŸ”´ **3 Critical** | ğŸŸ  **5 High** | ğŸŸ¡ **12 Medium**
Health Score: **62/100** (â†“ 8 from last analysis)

**Top Findings:**
1. SQL injection in `api/users.py:45` - User input unsanitized
2. Hardcoded credentials in `config/settings.py:23`
3. Missing auth check in `handlers/admin.py:112`

**Action Required:** Yes - Critical security issues found

---
<details>
<summary>ğŸ“‹ Show Details (Tier 2)</summary>

### Finding 1: SQL Injection
- **Location:** `api/users.py:45`
- **Severity:** Critical
- **Context:** Direct string concatenation in SQL query
- **Impact:** Allows arbitrary SQL execution, data breach risk
- **Fix:** Use parameterized queries with SQLAlchemy

[... more findings ...]
</details>

---
<details>
<summary>ğŸ” Show Evidence (Tier 3)</summary>

### Evidence Chain for Finding 1
**Auggie Query:** "SQL injection vulnerabilities in Python"
**Auggie Result:** (relevance: 0.92, confidence: 0.88)
```python
# api/users.py:45
query = f"SELECT * FROM users WHERE id = {user_input}"  # VULNERABLE
```

**Serena Validation:** Symbol `execute_query` found, 12 references
**Grep Confirmation:** Pattern `f"SELECT.*{` matched at line 45

**Cross-Session Context:** This file was flagged in 2 previous analyses
</details>
```

---

## 8. Adaptive Token Budgeting (NEW - ROI 6.50)

### Codebase Size Tier Multipliers

```yaml
adaptive_token_budgeting:
  size_detection:
    method: "Auggie initial query + file count heuristic"

  size_tiers:
    small:
      threshold: "< 10K LOC or < 100 files"
      multiplier: 1.0x
      sampling: 100%

    medium:
      threshold: "10K-100K LOC or 100-500 files"
      multiplier: 1.5x
      sampling: "30-50%"

    large:
      threshold: "100K-1M LOC or 500-2000 files"
      multiplier: 2.0x
      sampling: "10-20%"
      hierarchical: true

    massive:
      threshold: "> 1M LOC or > 2000 files"
      multiplier: 2.5x
      sampling: "5-10%"
      require_target: true
      hierarchical: true
```

### Budget Calculation Formula

```yaml
budget_calculation:
  formula: "base_budget Ã— size_multiplier Ã— aggressiveness_multiplier Ã— focus_count"

  example:
    base_budget: 15K (deep)
    size_tier: large (2.0x)
    aggressiveness: aggressive (1.3x)
    focus_areas: 2 (security, quality)

    calculation: "15K Ã— 2.0 Ã— 1.3 Ã— 1.5 = 58.5K tokens"

  caps:
    absolute_max: 100K tokens
    time_max: 10 minutes

  warnings:
    threshold_75: "Token budget 75% consumed"
    threshold_90: "Approaching token limit, summarizing"
```

---

## 9. Language-Aware Query Templates (NEW - ROI 6.43)

### Language Detection and Template Selection

```yaml
language_aware_queries:
  detection:
    method: "File extension analysis + Auggie initial query"

  templates:
    python:
      security:
        - "SQL injection vulnerabilities including f-string formatting"
        - "Pickle deserialization and untrusted data loading"
        - "__import__, exec, eval usage patterns"
        - "Django/Flask security misconfigurations"
      quality:
        - "Cyclomatic complexity exceeding 10"
        - "Functions with more than 5 parameters"
        - "Missing type hints in public APIs"
      performance:
        - "N+1 query patterns in ORM usage"
        - "Synchronous I/O in async contexts"
        - "Memory-inefficient list comprehensions"

    javascript_typescript:
      security:
        - "XSS vulnerabilities in DOM manipulation"
        - "Prototype pollution attack vectors"
        - "Insecure use of innerHTML or dangerouslySetInnerHTML"
        - "JWT handling and token storage issues"
      quality:
        - "Callback hell and promise anti-patterns"
        - "Missing error boundaries in React"
        - "Implicit any types in TypeScript"
      performance:
        - "Unnecessary re-renders in React components"
        - "Memory leaks in event listeners"
        - "Large bundle size contributors"

    go:
      security:
        - "SQL injection in database/sql queries"
        - "Path traversal in file operations"
        - "Insecure TLS configurations"
      quality:
        - "Error handling patterns (ignored errors)"
        - "Goroutine leaks and channel issues"
        - "Interface pollution"
      performance:
        - "Inefficient string concatenation"
        - "Unnecessary allocations in hot paths"
        - "Mutex contention patterns"

    java:
      security:
        - "SQL injection in JDBC and JPA"
        - "XXE vulnerabilities in XML parsing"
        - "Insecure deserialization patterns"
      quality:
        - "God classes exceeding 500 lines"
        - "Excessive inheritance depth"
        - "Missing null checks"
      performance:
        - "N+1 queries in Hibernate"
        - "Thread safety issues"
        - "Memory leaks in collections"
```

### Multi-Language Project Handling

```yaml
multi_language_strategy:
  detection: "Identify all languages > 10% of codebase"
  query_distribution:
    primary_language: 50% of queries
    secondary_languages: 30% shared
    cross_language: 20% for integration points

  cross_language_queries:
    - "API contracts between {lang1} and {lang2}"
    - "Data serialization at language boundaries"
    - "Authentication flow across services"
```

---

## 10. Iterative Query Refinement (NEW - ROI 6.23)

### Refinement Algorithm

```yaml
iterative_refinement:
  purpose: "Improve query precision based on initial results"

  algorithm:
    iteration_0:
      query: "Broad semantic query for {focus} in {language}"
      evaluate: quality_score

    iteration_n:
      condition: "quality_score < 0.7 AND iterations < max"
      refinement_strategies:
        narrow_scope:
          trigger: "Too many results (> 50)"
          action: "Add specificity: 'in {specific_module}'"
        broaden_scope:
          trigger: "Too few results (< 3)"
          action: "Remove constraints: 'any {focus} patterns'"
        rephrase:
          trigger: "Low relevance score"
          action: "Use alternative terminology from language docs"
        decompose:
          trigger: "Mixed relevance in results"
          action: "Split into 2-3 more specific queries"

  max_iterations:
    quick: 0
    deep: 1
    comprehensive: 3

  termination:
    success: "quality_score >= 0.7"
    timeout: "time_budget exhausted"
    max_reached: "iterations == max"
```

### Refinement Example

```yaml
refinement_example:
  iteration_0:
    query: "Security vulnerabilities in authentication"
    results: 127 matches
    quality_score: 0.45
    issue: "Too broad, many false positives"

  iteration_1:
    refinement: narrow_scope
    query: "SQL injection and credential handling in auth module"
    results: 23 matches
    quality_score: 0.72
    outcome: "Acceptable, proceed to analysis"
```

---

## 11. Hybrid Validation Pipeline (NEW - ROI 6.11)

### Three-Stage Validation Chain

```yaml
hybrid_validation_pipeline:
  purpose: "Multi-tool verification to reduce false positives"

  stages:
    stage_1_semantic:
      tool: mcp__auggie-mcp__codebase-retrieval
      validation: "Semantic relevance to finding"
      output: candidate_findings
      pass_threshold: relevance_score >= 0.6

    stage_2_structural:
      tool: find_symbol, find_referencing_symbols
      validation: "Symbol exists and has references"
      output: validated_findings
      pass_threshold: symbol_found AND references > 0

    stage_3_syntactic:
      tool: Grep
      validation: "Pattern actually present in code"
      output: confirmed_findings
      pass_threshold: pattern_matched

  confidence_assignment:
    all_3_pass: "HIGH confidence (0.9+)"
    stage_1_2_pass: "MEDIUM confidence (0.7-0.9)"
    stage_1_only: "LOW confidence (0.5-0.7)"

  fallback:
    serena_unavailable: "Skip stage 2, use stage 1 + 3"
    grep_timeout: "Accept stage 1 + 2 results"
```

### Validation Example

```yaml
validation_example:
  finding: "SQL injection in api/users.py"

  stage_1:
    query: "SQL injection in user API"
    result: "api/users.py mentioned with relevance 0.91"
    status: PASS

  stage_2:
    operation: "find_symbol execute_query in api/users.py"
    result: "Symbol found at line 45, 12 references"
    status: PASS

  stage_3:
    pattern: "f\"SELECT.*\\{.*\\}\""
    result: "Match at api/users.py:45"
    status: PASS

  final_confidence: HIGH (0.94)
```

---

## 12. Auggie Result Quality Scoring (NEW - ROI 5.53)

### Quality Metrics

```yaml
auggie_quality_scoring:
  metrics:
    relevance_score:
      description: "How well results match the query intent"
      calculation: "semantic_similarity(query, results)"
      range: 0.0 - 1.0
      threshold: 0.6 minimum

    completeness_score:
      description: "Coverage of the focus area"
      calculation: "matched_areas / expected_areas"
      range: 0.0 - 1.0
      threshold: 0.5 minimum

    confidence_score:
      description: "Overall quality metric"
      calculation: "(relevance Ã— 0.6) + (completeness Ã— 0.4)"
      range: 0.0 - 1.0
      threshold: 0.7 for actionable findings

  actions_by_score:
    high_quality:
      range: ">= 0.8"
      action: "Proceed with analysis"

    acceptable:
      range: "0.6 - 0.8"
      action: "Proceed with validation emphasis"

    low_quality:
      range: "0.4 - 0.6"
      action: "Trigger iterative refinement"

    poor_quality:
      range: "< 0.4"
      action: "Fall back to native tools or rephrase"
```

### Scoring Display

```yaml
scoring_display:
  format: "ğŸ¯ Query: '{query}' | Relevance: {rel}/1.0 | Completeness: {comp}/1.0 | Confidence: {conf}/1.0"

  example:
    query: "Security vulnerabilities in authentication"
    relevance: 0.85
    completeness: 0.72
    confidence: 0.80
    display: "ğŸ¯ Query: 'Security vulnerabilities...' | Relevance: 0.85 | Completeness: 0.72 | Confidence: 0.80 âœ“"
```

---

## 13. Cross-Session Analysis Memory (NEW - ROI 6.71)

### Memory Architecture

```yaml
cross_session_memory:
  storage: "Serena write_memory / read_memory"

  memory_schema:
    project_hash:
      calculation: "hash(project_root + git_commit_short)"

    memory_keys:
      analysis_latest: "analysis_{project_hash}_latest"
      analysis_history: "analysis_{project_hash}_history"
      patterns_learned: "patterns_{project_hash}"

  stored_data:
    findings:
      - finding_id
      - severity
      - location
      - first_detected_date
      - status: new|recurring|resolved

    patterns:
      - common_issues: ["pattern1", "pattern2"]
      - hot_spots: ["file1.py", "module2/"]
      - improvement_trend: [score_t1, score_t2, ...]

    metadata:
      - last_analysis_date
      - analysis_depth
      - focus_areas
      - token_usage
```

### Cross-Session Operations

```yaml
cross_session_operations:
  on_analysis_start:
    - read_memory("analysis_{project_hash}_latest")
    - compare_git_state: "has code changed since last analysis?"
    - load_known_patterns: "patterns_{project_hash}"

  on_analysis_complete:
    - delta_calculation: "new findings vs previous"
    - update_memory: "analysis_{project_hash}_latest"
    - append_history: "analysis_{project_hash}_history"
    - update_patterns: "patterns_{project_hash}"

  delta_reporting:
    new_findings: "ğŸ†• 5 new issues found"
    resolved_findings: "âœ… 3 issues resolved since last analysis"
    recurring_findings: "ğŸ” 7 recurring issues (consider prioritizing)"
    trend: "ğŸ“ˆ Health score improved from 58 to 67"
```

---

## 14. Real-Time Degradation Feedback (NEW - ROI 5.42)

### User Feedback System

```yaml
degradation_feedback:
  purpose: "Inform users when operating in reduced capability mode"

  triggers:
    auggie_unavailable:
      message: "âš ï¸ Semantic search unavailable - using pattern matching (reduced precision)"
      impact: "~50% higher false positive rate expected"

    serena_unavailable:
      message: "âš ï¸ Symbol analysis unavailable - using file-based analysis"
      impact: "Cross-reference tracking disabled"

    sequential_unavailable:
      message: "âš ï¸ Advanced reasoning unavailable - using direct synthesis"
      impact: "Complex root cause analysis may be limited"

    partial_degradation:
      message: "âš ï¸ Running in hybrid mode: {available_tools}"
      impact: "Some analysis capabilities reduced"

  display_format:
    banner: "â”Œâ”€ DEGRADATION NOTICE â”€â”\nâ”‚ {message} â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
    inline: "âš ï¸ {message}"

  recovery_notification:
    on_recovery: "âœ… Full capability restored - {tool} reconnected"
```

### Circuit Breaker Integration

```yaml
circuit_breaker_with_feedback:
  auggie_circuit:
    failure_threshold: 3
    timeout: 30s
    fallback: "Native Glob + Grep discovery"
    user_message: "âš ï¸ Semantic search circuit open - using fallback"
    recovery: "Half-open after 60s"
    recovery_message: "âœ… Testing semantic search recovery..."

  serena_circuit:
    failure_threshold: 4
    timeout: 45s
    fallback: "Read target files directly"
    user_message: "âš ï¸ Symbol analysis circuit open - using file reads"
    recovery: "Half-open after 60s"
```

---

## 15. MCP Integration Architecture

### Tool Coordination Matrix

```yaml
tool_coordination:
  planning_phase:
    primary: mcp__auggie-mcp__codebase-retrieval
    parameters:
      directory_path: "{project_root}"  # REQUIRED
      information_request: "Project structure and architecture"
    operations:
      - "Load project context and architecture"
      - "Detect codebase size and languages"
      - "Identify focus-relevant entry points"
    fallback: "Glob for file enumeration"
    degradation_feedback: true

  discovery_phase:
    primary: mcp__auggie-mcp__codebase-retrieval
    parameters:
      directory_path: "{project_root}"  # REQUIRED
      information_request: "{language_aware_query}"
    operations:
      - "Focus-specific semantic queries"
      - "Language-aware pattern detection"
      - "Iterative refinement if quality < 0.7"
    fallback: "Grep with pre-defined patterns"
    quality_scoring: true

  analysis_phase:
    primary: [find_symbol, find_referencing_symbols]
    validation: Grep (hybrid pipeline)
    operations:
      - "Symbol-level analysis for complex findings"
      - "Dependency tracking for impact assessment"
      - "Three-stage validation chain"
    fallback: "Read target files directly"

  synthesis_phase:
    primary: mcp__sequential-thinking__sequentialthinking
    operations:
      - "Multi-step reasoning for root causes"
      - "Aggregate and prioritize findings"
      - "Cross-session delta analysis"
    fallback: "Direct synthesis in response"

  report_phase:
    tools: [Write, write_memory]
    operations:
      - "Generate progressive disclosure report"
      - "Cache results for cross-session reference"
      - "Update analysis history"
```

---

## 16. Implementation Roadmap (Revised by ROI)

### Phase 1: Critical Fixes + P1 Improvements (Week 1-2)

**Priority**: P0 - Must fix before any other work

| Task | ROI | Effort | Description |
|------|-----|--------|-------------|
| Fix MCP tool name | N/A | Low | Change "auggie-mcp" â†’ "mcp__auggie-mcp__codebase-retrieval" |
| Add directory_path | N/A | Low | Required parameter for all Auggie calls |
| Progressive Disclosure | 7.01 | Medium | Implement 3-tier output system |
| Tier Classification | 6.83 | Medium | Integrate with sc:task-unified |
| Cross-Session Memory | 6.71 | Medium | Implement Serena memory operations |

### Phase 2: P2 Improvements (Week 3-4)

| Task | ROI | Effort | Description |
|------|-----|--------|-------------|
| Adaptive Token Budgeting | 6.50 | Low | Size-based budget multipliers |
| Language-Aware Templates | 6.43 | Medium | Per-language query templates |
| Iterative Refinement | 6.23 | Medium | Query refinement algorithm |
| Hybrid Validation | 6.11 | Medium | 3-stage validation pipeline |
| --aggressiveness Flag | 6.10 | Low | User control flag |

### Phase 3: P3 Improvements + Hardening (Week 5-6)

| Task | ROI | Effort | Description |
|------|-----|--------|-------------|
| Quality Scoring | 5.53 | Low | Auggie result metrics |
| Degradation Feedback | 5.42 | Low | Real-time user notifications |
| Performance Monitoring | N/A | Low | Metrics and alerting |
| Documentation | N/A | Low | Examples and guides |

---

## 17. Success Metrics (Updated)

### Performance Targets

| Metric | Current | Target | Measurement |
|--------|---------|--------|-------------|
| Token consumption (quick) | 15-50K | 5-8K | Per analysis |
| Token consumption (deep) | 50-200K | 15-25K | Per analysis |
| Latency (quick) | 20-40s | 8-15s | End-to-end |
| Latency (deep) | 60-180s | 30-60s | End-to-end |
| False positive rate | ~50% | < 10% | User dismissals |

### Quality Metrics

| Metric | Current | Target | Measurement |
|--------|---------|--------|-------------|
| Analysis Precision | ~40% | >= 85% | Hybrid validation |
| Analysis Recall | ~60% | >= 90% | Known issue detection |
| Evidence Quality | N/A | >= 0.7 | Confidence scores |
| Cross-Session Delta Accuracy | N/A | >= 95% | Finding tracking |

---

## 18. Risk Assessment (Updated)

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Auggie MCP unavailable | Medium | High | Circuit breaker + degradation feedback |
| Query latency exceeds budget | Low | Medium | Adaptive budgeting + early termination |
| False positive rate unchanged | Low | High | Hybrid validation pipeline |
| Large codebase performance | Medium | Medium | Adaptive token budgeting |
| User confusion with aggressiveness | Low | Low | Clear documentation + defaults |
| Cross-session memory corruption | Low | Medium | Validation on load + backup |

---

## Appendix A: Updated analyze.md Template

```yaml
---
name: analyze
description: "Semantic code analysis across quality, security, performance, and architecture domains"
category: utility
complexity: standard
mcp-servers: [mcp__auggie-mcp__codebase-retrieval, mcp__sequential-thinking__sequentialthinking]
mcp-optional: [serena]
personas: [analyzer, security, performance, architect]
fallback-enabled: true
tier-classification: auto
progressive-disclosure: true
---

# /sc:analyze - Semantic Code Analysis

## Triggers
- Code quality assessment requests
- Security vulnerability scanning
- Performance bottleneck identification
- Architecture review requirements

## Usage
```
/sc:analyze [target] [options]

Options:
  --focus quality|security|performance|architecture  (default: all)
  --depth quick|deep|comprehensive                   (default: deep)
  --aggressiveness minimal|balanced|aggressive|maximum (default: balanced)
  --tier STRICT|STANDARD|LIGHT|EXEMPT               (default: auto)
  --format text|json|report                          (default: text)
  --verbose                                          (show details tier)
  --evidence                                         (show evidence tier)
```

## Behavioral Flow

### 1. Classify & Configure
- Detect codebase size and languages
- Determine tier classification (auto or user-specified)
- Calculate adaptive token budget
- Configure aggressiveness level

### 2. Semantic Discovery
- Execute language-aware Auggie queries
- Apply iterative refinement if quality < 0.7
- Parallel execution for multiple focus areas

### 3. Validated Analysis
- Hybrid validation pipeline (Auggie â†’ Serena â†’ Grep)
- Quality scoring for all findings
- Cross-reference tracking for impact

### 4. Synthesis with Memory
- Cross-session delta analysis
- Root cause reasoning with Sequential
- Pattern learning and storage

### 5. Progressive Disclosure Report
- Summary tier: Key findings and health score
- Details tier: Actionable information (on request)
- Evidence tier: Full audit trail (on request)

## MCP Integration
- **Required**: mcp__auggie-mcp__codebase-retrieval (with directory_path)
- **Recommended**: mcp__sequential-thinking__sequentialthinking
- **Optional**: serena (symbols + memory)
- **Fallback**: Native tools with degradation feedback

## Boundaries

**Will:**
- Perform semantic code analysis with evidence chains
- Generate severity-rated findings with confidence scores
- Scale to large codebases with adaptive budgeting
- Provide user-controllable aggressiveness levels
- Track findings across sessions

**Will Not:**
- Execute dynamic analysis requiring runtime
- Modify source code without explicit consent
- Proceed silently when in degraded mode
- Exceed token budgets without warning
```

---

*Document Version 2.0.0 - Spec-Panel Reviewed*
*Incorporating 10 improvements prioritized by ROI score*
*Expert reviewers: Wiegers, Fowler, Nygard, Adzic, Crispin*
